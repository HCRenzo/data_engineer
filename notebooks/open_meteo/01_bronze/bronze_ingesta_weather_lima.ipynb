{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99766923-4a3b-4927-80ae-eeeb555bc850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a764fde9-4ba8-4965-b9c1-66439cfb2b86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Cargar el .env\n",
    "load_dotenv(\"/Workspace/Users/renzo_hc@outlook.com/data_engineer/.env\")\n",
    "\n",
    "# URL del JSON público en S3\n",
    "url = os.getenv(\"BASE_URL_OPENMETEO\")\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Fecha de ingesta actual\n",
    "fecha_ingesta = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Construcción de filas\n",
    "rows = [\n",
    "    (\n",
    "        str(uuid.uuid4()),\n",
    "        r[\"distrito\"],\n",
    "        r[\"lat\"],\n",
    "        r[\"lon\"],\n",
    "        r[\"fecha\"],\n",
    "        r[\"temp_max\"],\n",
    "        r[\"temp_min\"],\n",
    "        r[\"precipitacion\"],\n",
    "        fecha_ingesta\n",
    "    )\n",
    "    for r in data\n",
    "]\n",
    "\n",
    "# Definir esquema con nombres descriptivos\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"distrito\", StringType(), True),\n",
    "    StructField(\"latitud\", DoubleType(), True),\n",
    "    StructField(\"longitud\", DoubleType(), True),\n",
    "    StructField(\"fecha\", StringType(), True),\n",
    "    StructField(\"temperatura_maxima\", DoubleType(), True),\n",
    "    StructField(\"temperatura_minima\", DoubleType(), True),\n",
    "    StructField(\"precipitacion_total\", DoubleType(), True),\n",
    "    StructField(\"fecha_ingesta\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Crear DataFrame\n",
    "df = spark.createDataFrame(rows, schema=schema)\n",
    "\n",
    "# Tabla destino\n",
    "tabla_bronze = \"main.weather.bronze_distritos_diarios\"\n",
    "\n",
    "# Verificar existencia de la tabla y aplicar lógica de ingesta incremental\n",
    "if not spark.catalog.tableExists(tabla_bronze):\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(tabla_bronze)\n",
    "    print(\"✅ Tabla creada e ingesta inicial completada.\")\n",
    "else:\n",
    "    df_existente = spark.table(tabla_bronze)\n",
    "    df_nuevos = df.join(df_existente, [\"distrito\", \"fecha\"], \"left_anti\")\n",
    "    \n",
    "    nuevos_registros = df_nuevos.count()\n",
    "    if nuevos_registros > 0:\n",
    "        df_nuevos.write.format(\"delta\").mode(\"append\").saveAsTable(tabla_bronze)\n",
    "        print(f\"✅ {nuevos_registros} nuevos registros insertados.\")\n",
    "    else:\n",
    "        print(\"ℹ️ No se encontraron nuevos datos para insertar.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingesta_weather_lima",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
