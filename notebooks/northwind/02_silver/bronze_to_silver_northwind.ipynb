{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8970a39a-7ca4-41b6-8153-6fe2069f1519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SILVER INGESTA - NORTHWIND\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql.functions import col, to_date, lit\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# --------------------------------------------\n",
    "# CONFIGURACI√ìN\n",
    "# --------------------------------------------\n",
    "catalog = \"northwind\"\n",
    "bronze_schema = \"bronze\"\n",
    "silver_schema = \"silver\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "spark.sql(f\"USE SCHEMA {silver_schema}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# LISTA DE TABLAS EN BRONZE\n",
    "# --------------------------------------------\n",
    "tables = [\n",
    "    \"categories\",\n",
    "    \"customers\",\n",
    "    \"employee_territories\",\n",
    "    \"employees\",\n",
    "    \"order_details\",\n",
    "    \"orders\",\n",
    "    \"products\",\n",
    "    \"regions\",\n",
    "    \"shippers\",\n",
    "    \"suppliers\",\n",
    "    \"territories\"\n",
    "]\n",
    "\n",
    "# --------------------------------------------\n",
    "# FUNCIONES DE LIMPIEZA\n",
    "# --------------------------------------------\n",
    "\n",
    "def camel_to_snake(name):\n",
    "    \"\"\"\n",
    "    Converts camelCase or PascalCase to snake_case.\n",
    "    \"\"\"\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "def limpiar_columnas(df):\n",
    "    \"\"\"\n",
    "    Normaliza nombres de columnas a snake_case\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        new_name = camel_to_snake(c.strip().replace(\" \", \"_\"))\n",
    "        df = df.withColumnRenamed(c, new_name)\n",
    "    return df\n",
    "\n",
    "def convertir_fechas(df, cols):\n",
    "    \"\"\"\n",
    "    Convierte columnas de fecha en formato DATE\n",
    "    \"\"\"\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, to_date(col(c)))\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------\n",
    "# INGESTA DE TABLAS A SILVER\n",
    "# --------------------------------------------\n",
    "\n",
    "for table in tables:\n",
    "    try:\n",
    "        print(f\"üì• Procesando Bronze Table: {table}\")\n",
    "\n",
    "        # 1Ô∏è‚É£ Leer desde Bronze\n",
    "        df = spark.table(f\"{bronze_schema}.{table}\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Limpiar nombres de columnas (snake_case)\n",
    "        df = limpiar_columnas(df)\n",
    "\n",
    "        # 3Ô∏è‚É£ Convertir columnas de fecha si aplican\n",
    "        df = convertir_fechas(df, [\"order_date\", \"required_date\", \"shipped_date\"])\n",
    "\n",
    "        # 4Ô∏è‚É£ Agregar columnas de auditor√≠a\n",
    "        ingest_date = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        source_system = 'northwind_csv'\n",
    "        ingest_user = 'databricks_pipeline'\n",
    "        load_id = str(uuid.uuid4())\n",
    "\n",
    "        df = df.withColumn(\"ingest_date\", lit(ingest_date)) \\\n",
    "               .withColumn(\"source_file\", lit(f\"{table}.csv\")) \\\n",
    "               .withColumn(\"source_system\", lit(source_system)) \\\n",
    "               .withColumn(\"ingest_user\", lit(ingest_user)) \\\n",
    "               .withColumn(\"load_id\", lit(load_id))\n",
    "\n",
    "        # 5Ô∏è‚É£ Escribir como tabla Delta en Silver con prefijo t_\n",
    "        delta_table = f\"{silver_schema}.t_{table}\"\n",
    "        df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(delta_table)\n",
    "\n",
    "        print(f\"‚úÖ Silver Table creada: {delta_table}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error procesando {table}: {e}\")\n",
    "\n",
    "print(\"üöÄ Ingesta Silver completa ‚úÖ\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_to_silver_northwind",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
